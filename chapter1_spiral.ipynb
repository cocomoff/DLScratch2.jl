{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\".\\\\common\\\\layers.jl\")\n",
    "using Main.JLlayers\n",
    "using DelimitedFiles\n",
    "using Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read spiral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×3 Array{Float64,2}:\n",
       " -0.0     0.0     0.0\n",
       " -0.001   0.01    0.0\n",
       "  0.0051  0.0193  0.0\n",
       " -0.0004  0.03    0.0\n",
       "  0.0143  0.0374  0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = readdlm(\"data/sprial.dat\");\n",
    "data[1:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one_hot (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function one_hot(x::Array{Float64, 1}; num=3)\n",
    "    ans = zeros(size(x)[1], num)\n",
    "    for i in 1:size(x)[1]\n",
    "        idx = Int(x[i]) + 1\n",
    "        ans[i, idx] = 1\n",
    "    end\n",
    "    return ans\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0 0.0; -0.001 0.01; 0.0051 0.0193; -0.0004 0.03; 0.0143 0.0374],(5, 2)\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0],(5,)\n",
      "[1.0 0.0 0.0; 1.0 0.0 0.0; 1.0 0.0 0.0; 1.0 0.0 0.0; 1.0 0.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "x1 = data[1:5, 1:2]\n",
    "t1 = data[1:5, 3]\n",
    "to = one_hot(t1)\n",
    "println(x1, \",\", size(x1))\n",
    "println(t1, \",\", size(t1))\n",
    "println(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TwoLayerNet{Float64}(AffineLayer{Float64}([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], #undef, [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), SigmoidLayer{Float64}(#undef), AffineLayer{Float64}([0.0 0.0 0.0; 0.0 0.0 0.0; … ; 0.0 0.0 0.0; 0.0 0.0 0.0], [0.0, 0.0, 0.0], #undef, [0.0 0.0 0.0; 0.0 0.0 0.0; … ; 0.0 0.0 0.0; 0.0 0.0 0.0], [0.0, 0.0, 0.0]), SoftmaxWithLossLayer{Float64}(3.9282128e-316, #undef, #undef))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "hidden_size = 10\n",
    "data_size = size(x1)[1]\n",
    "max_iters = data_size // batch_size\n",
    "net = TwoLayerNet{Float64}(2, hidden_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0986121886681097\n",
      "(1.0986121886681097, Main.JLlayers.TwoLayerNetGrads{Float64}([0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [-0.333333 0.166667 0.166667; -0.333333 0.166667 0.166667; -0.333333 0.166667 0.166667; -0.333333 0.166667 0.166667; -0.333333 0.166667 0.166667; -0.333333 0.166667 0.166667; -0.333333 0.166667 0.166667; -0.333333 0.166667 0.166667; -0.333333 0.166667 0.166667; -0.333333 0.166667 0.166667], [-0.666667, 0.333333, 0.333333]))\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet{Float64}(2, 10, 3)\n",
    "println(forward(net, x1, to))\n",
    "ypred = predict(net, x1[:, :])\n",
    "println(gradient(net, x1, to))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 1;\n",
    "batch_size = 30;\n",
    "hidden_size = 10;\n",
    "learning_rate = 0.1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TwoLayerNet{Float64}(AffineLayer{Float64}([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], #undef, [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), SigmoidLayer{Float64}(#undef), AffineLayer{Float64}([0.0 0.0 0.0; 0.0 0.0 0.0; … ; 0.0 0.0 0.0; 0.0 0.0 0.0], [0.0, 0.0, 0.0], #undef, [0.0 0.0 0.0; 0.0 0.0 0.0; … ; 0.0 0.0 0.0; 0.0 0.0 0.0], [0.0, 0.0, 0.0]), SoftmaxWithLossLayer{Float64}(5.7488506e-316, #undef, #undef))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data[:, 1:2]\n",
    "t = data[:, 3]\n",
    "to = one_hot(t)\n",
    "data_size = size(x)[1]\n",
    "max_iters = data_size // batch_size\n",
    "net = TwoLayerNet{Float64}(2, hidden_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1   loss 1.893694548041942\n",
      "epoch 2   loss 2.040286908915635\n",
      "epoch 3   loss 1.8535330473622547\n",
      "epoch 4   loss 1.7153077229713063\n",
      "epoch 5   loss 1.623138842249491\n",
      "epoch 6   loss 1.5599221967750712\n",
      "epoch 7   loss 1.5151506006211044\n",
      "epoch 8   loss 1.4824242275520274\n",
      "epoch 9   loss 1.4578077383467642\n",
      "epoch 10   loss 1.4388164908643024\n",
      "epoch 11   loss 1.423834947275846\n",
      "epoch 12   loss 1.4117827877300548\n",
      "epoch 13   loss 1.401918591890376\n",
      "epoch 14   loss 1.3937212226387714\n",
      "epoch 15   loss 1.386816262993173\n",
      "epoch 16   loss 1.38092926037995\n",
      "epoch 17   loss 1.3758553152465018\n",
      "epoch 18   loss 1.3714388671747708\n",
      "epoch 19   loss 1.367559984073432\n",
      "epoch 20   loss 1.36412488526467\n",
      "epoch 21   loss 1.3610592755378281\n",
      "epoch 22   loss 1.3583035801978567\n",
      "epoch 23   loss 1.355809488304407\n",
      "epoch 24   loss 1.3535374111927871\n",
      "epoch 25   loss 1.351454591694927\n",
      "epoch 26   loss 1.3495336833485765\n",
      "epoch 27   loss 1.3477516746784146\n",
      "epoch 28   loss 1.3460890714342129\n",
      "epoch 29   loss 1.3445292757945657\n",
      "epoch 30   loss 1.3430581200199183\n",
      "epoch 31   loss 1.341663525484881\n",
      "epoch 32   loss 1.3403352681698166\n",
      "epoch 33   loss 1.3390648397058846\n",
      "epoch 34   loss 1.337845399717923\n",
      "epoch 35   loss 1.3366718209740718\n",
      "epoch 36   loss 1.335540833943082\n",
      "epoch 37   loss 1.3344512816976009\n",
      "epoch 38   loss 1.3334044992206058\n",
      "epoch 39   loss 1.3324048320923647\n",
      "epoch 40   loss 1.3314603066018218\n",
      "epoch 41   loss 1.3305834540957602\n",
      "epoch 42   loss 1.3297922736889718\n",
      "epoch 43   loss 1.3291112859085943\n",
      "epoch 44   loss 1.328572582978029\n",
      "epoch 45   loss 1.3282167198330541\n",
      "epoch 46   loss 1.328093220033283\n",
      "epoch 47   loss 1.3282604074157653\n",
      "epoch 48   loss 1.3287842417311055\n",
      "epoch 49   loss 1.3297358644656228\n",
      "epoch 50   loss 1.3311876767668611\n",
      "epoch 51   loss 1.3332079873224498\n",
      "epoch 52   loss 1.3358545698111475\n",
      "epoch 53   loss 1.3391678074906317\n",
      "epoch 54   loss 1.3431643910668334\n",
      "epoch 55   loss 1.347832667746123\n",
      "epoch 56   loss 1.3531306205623586\n",
      "epoch 57   loss 1.3589870595280618\n",
      "epoch 58   loss 1.3653060067211231\n",
      "epoch 59   loss 1.3719736277077632\n",
      "epoch 60   loss 1.3788665989392477\n",
      "epoch 61   loss 1.3858606370743303\n",
      "epoch 62   loss 1.392838064019484\n",
      "epoch 63   loss 1.3996936452181874\n",
      "epoch 64   loss 1.406338374892703\n",
      "epoch 65   loss 1.4127012648090755\n",
      "epoch 66   loss 1.4187294521260383\n",
      "epoch 67   loss 1.424387064200557\n",
      "epoch 68   loss 1.4296532897106378\n",
      "epoch 69   loss 1.4345200469516253\n",
      "epoch 70   loss 1.4389895500867804\n",
      "epoch 71   loss 1.443071980225729\n",
      "epoch 72   loss 1.4467833863055826\n",
      "epoch 73   loss 1.4501438772484339\n",
      "epoch 74   loss 1.4531761221346327\n",
      "epoch 75   loss 1.455904146476546\n",
      "epoch 76   loss 1.4583523963809852\n",
      "epoch 77   loss 1.4605450348330233\n",
      "epoch 78   loss 1.4625054325119986\n",
      "epoch 79   loss 1.4642558171902051\n",
      "epoch 80   loss 1.4658170492674363\n",
      "epoch 81   loss 1.4672084953019842\n",
      "epoch 82   loss 1.4684479758523588\n",
      "epoch 83   loss 1.4695517681640413\n",
      "epoch 84   loss 1.4705346480271386\n",
      "epoch 85   loss 1.4714099584159697\n",
      "epoch 86   loss 1.4721896952927944\n",
      "epoch 87   loss 1.4728846032466425\n",
      "epoch 88   loss 1.4735042754954555\n",
      "epoch 89   loss 1.4740572542635293\n",
      "epoch 90   loss 1.4745511287145194\n",
      "epoch 91   loss 1.4749926285270278\n",
      "epoch 92   loss 1.4753877118931615\n",
      "epoch 93   loss 1.475741647242109\n",
      "epoch 94   loss 1.4760590883758817\n",
      "epoch 95   loss 1.4763441429822954\n",
      "epoch 96   loss 1.4766004346849217\n",
      "epoch 97   loss 1.4768311589206273\n",
      "epoch 98   loss 1.4770391330179162\n",
      "epoch 99   loss 1.4772268408959675\n",
      "epoch 100   loss 1.4773964728246263\n",
      "epoch 101   loss 1.4775499606871805\n",
      "epoch 102   loss 1.4776890091762818\n",
      "epoch 103   loss 1.4778151233332408\n",
      "epoch 104   loss 1.4779296328153617\n",
      "epoch 105   loss 1.478033713247486\n",
      "epoch 106   loss 1.4781284049841603\n",
      "epoch 107   loss 1.4782146295791294\n",
      "epoch 108   loss 1.4782932042299968\n",
      "epoch 109   loss 1.4783648544384889\n",
      "epoch 110   loss 1.4784302251011172\n",
      "epoch 111   loss 1.4784898902213424\n",
      "epoch 112   loss 1.478544361412693\n",
      "epoch 113   loss 1.4785940953426422\n",
      "epoch 114   loss 1.4786395002493482\n",
      "epoch 115   loss 1.4786809416474749\n",
      "epoch 116   loss 1.4787187473252077\n",
      "epoch 117   loss 1.4787532117219517\n",
      "epoch 118   loss 1.4787845997651228\n",
      "epoch 119   loss 1.4788131502345863\n",
      "epoch 120   loss 1.478839078714654\n",
      "epoch 121   loss 1.4788625801859645\n",
      "epoch 122   loss 1.4788838313028863\n",
      "epoch 123   loss 1.478902992396249\n",
      "epoch 124   loss 1.4789202092361156\n",
      "epoch 125   loss 1.4789356145848385\n",
      "epoch 126   loss 1.4789493295667453\n",
      "epoch 127   loss 1.4789614648774276\n",
      "epoch 128   loss 1.4789721218526302\n",
      "epoch 129   loss 1.4789813934141782\n",
      "epoch 130   loss 1.478989364908123\n",
      "epoch 131   loss 1.4789961148483628\n",
      "epoch 132   loss 1.4790017155772734\n",
      "epoch 133   loss 1.4790062338534191\n",
      "epoch 134   loss 1.4790097313751427\n",
      "epoch 135   loss 1.4790122652476942\n",
      "epoch 136   loss 1.4790138884006037\n",
      "epoch 137   loss 1.479014649961168\n",
      "epoch 138   loss 1.4790145955891534\n",
      "epoch 139   loss 1.479013767777219\n",
      "epoch 140   loss 1.4790122061209767\n",
      "epoch 141   loss 1.4790099475621372\n",
      "epoch 142   loss 1.4790070266077608\n",
      "epoch 143   loss 1.4790034755282684\n",
      "epoch 144   loss 1.4789993245365454\n",
      "epoch 145   loss 1.4789946019501898\n",
      "epoch 146   loss 1.4789893343387173\n",
      "epoch 147   loss 1.4789835466573111\n",
      "epoch 148   loss 1.4789772623685296\n",
      "epoch 149   loss 1.4789705035532186\n",
      "epoch 150   loss 1.4789632910117232\n",
      "epoch 151   loss 1.4789556443563807\n",
      "epoch 152   loss 1.4789475820961577\n",
      "epoch 153   loss 1.4789391217142052\n",
      "epoch 154   loss 1.4789302797390083\n",
      "epoch 155   loss 1.4789210718097505\n",
      "epoch 156   loss 1.4789115127364307\n",
      "epoch 157   loss 1.4789016165552178\n",
      "epoch 158   loss 1.4788913965794823\n",
      "epoch 159   loss 1.478880865446893\n",
      "epoch 160   loss 1.478870035162927\n",
      "epoch 161   loss 1.4788589171411064\n",
      "epoch 162   loss 1.4788475222402517\n",
      "epoch 163   loss 1.4788358607989944\n",
      "epoch 164   loss 1.4788239426677925\n",
      "epoch 165   loss 1.4788117772386418\n",
      "epoch 166   loss 1.4787993734726874\n",
      "epoch 167   loss 1.4787867399258947\n",
      "epoch 168   loss 1.4787738847729304\n",
      "epoch 169   loss 1.4787608158294132\n",
      "epoch 170   loss 1.478747540572643\n",
      "epoch 171   loss 1.4787340661609318\n",
      "epoch 172   loss 1.4787203994516473\n",
      "epoch 173   loss 1.4787065470180585\n",
      "epoch 174   loss 1.4786925151650785\n",
      "epoch 175   loss 1.4786783099439809\n",
      "epoch 176   loss 1.478663937166173\n",
      "epoch 177   loss 1.478649402416078\n",
      "epoch 178   loss 1.4786347110632099\n",
      "epoch 179   loss 1.4786198682734812\n",
      "epoch 180   loss 1.47860487901981\n",
      "epoch 181   loss 1.4785897480920625\n",
      "epoch 182   loss 1.4785744801063907\n",
      "epoch 183   loss 1.4785590795139945\n",
      "epoch 184   loss 1.478543550609356\n",
      "epoch 185   loss 1.4785278975379765\n",
      "epoch 186   loss 1.478512124303648\n",
      "epoch 187   loss 1.478496234775299\n",
      "epoch 188   loss 1.4784802326934314\n",
      "epoch 189   loss 1.4784641216761834\n",
      "epoch 190   loss 1.4784479052250366\n",
      "epoch 191   loss 1.4784315867301987\n",
      "epoch 192   loss 1.4784151694756698\n",
      "epoch 193   loss 1.4783986566440288\n",
      "epoch 194   loss 1.4783820513209416\n",
      "epoch 195   loss 1.478365356499417\n",
      "epoch 196   loss 1.4783485750838323\n",
      "epoch 197   loss 1.478331709893724\n",
      "epoch 198   loss 1.4783147636673797\n",
      "epoch 199   loss 1.4782977390652268\n",
      "epoch 200   loss 1.4782806386730427\n",
      "epoch 201   loss 1.4782634650049906\n",
      "epoch 202   loss 1.4782462205064877\n",
      "epoch 203   loss 1.4782289075569286\n",
      "epoch 204   loss 1.4782115284722603\n",
      "epoch 205   loss 1.4781940855074263\n",
      "epoch 206   loss 1.4781765808586789\n",
      "epoch 207   loss 1.4781590166657765\n",
      "epoch 208   loss 1.4781413950140672\n",
      "epoch 209   loss 1.4781237179364684\n",
      "epoch 210   loss 1.4781059874153428\n",
      "epoch 211   loss 1.4780882053842874\n",
      "epoch 212   loss 1.4780703737298264\n",
      "epoch 213   loss 1.4780524942930295\n",
      "epoch 214   loss 1.478034568871045\n",
      "epoch 215   loss 1.4780165992185625\n",
      "epoch 216   loss 1.4779985870492052\n",
      "epoch 217   loss 1.477980534036858\n",
      "epoch 218   loss 1.4779624418169302\n",
      "epoch 219   loss 1.4779443119875637\n",
      "epoch 220   loss 1.4779261461107827\n",
      "epoch 221   loss 1.477907945713595\n",
      "epoch 222   loss 1.4778897122890378\n",
      "epoch 223   loss 1.4778714472971866\n",
      "epoch 224   loss 1.4778531521661085\n",
      "epoch 225   loss 1.4778348282927865\n",
      "epoch 226   loss 1.4778164770439908\n",
      "epoch 227   loss 1.477798099757127\n",
      "epoch 228   loss 1.4777796977410353\n",
      "epoch 229   loss 1.4777612722767715\n",
      "epoch 230   loss 1.4777428246183395\n",
      "epoch 231   loss 1.4777243559934095\n",
      "epoch 232   loss 1.477705867603996\n",
      "epoch 233   loss 1.4776873606271175\n",
      "epoch 234   loss 1.4776688362154262\n",
      "epoch 235   loss 1.4776502954978132\n",
      "epoch 236   loss 1.4776317395799956\n",
      "epoch 237   loss 1.4776131695450725\n",
      "epoch 238   loss 1.4775945864540736\n",
      "epoch 239   loss 1.4775759913464754\n",
      "epoch 240   loss 1.4775573852407073\n",
      "epoch 241   loss 1.4775387691346338\n",
      "epoch 242   loss 1.4775201440060288\n",
      "epoch 243   loss 1.477501510813021\n",
      "epoch 244   loss 1.477482870494536\n",
      "epoch 245   loss 1.477464223970717\n",
      "epoch 246   loss 1.4774455721433353\n",
      "epoch 247   loss 1.4774269158961855\n",
      "epoch 248   loss 1.4774082560954662\n",
      "epoch 249   loss 1.477389593590155\n",
      "epoch 250   loss 1.4773709292123667\n",
      "epoch 251   loss 1.4773522637777008\n",
      "epoch 252   loss 1.4773335980855822\n",
      "epoch 253   loss 1.4773149329195874\n",
      "epoch 254   loss 1.4772962690477656\n",
      "epoch 255   loss 1.4772776072229472\n",
      "epoch 256   loss 1.4772589481830458\n",
      "epoch 257   loss 1.4772402926513493\n",
      "epoch 258   loss 1.4772216413368067\n",
      "epoch 259   loss 1.4772029949343044\n",
      "epoch 260   loss 1.4771843541249352\n",
      "epoch 261   loss 1.4771657195762622\n",
      "epoch 262   loss 1.4771470919425749\n",
      "epoch 263   loss 1.4771284718651363\n",
      "epoch 264   loss 1.4771098599724302\n",
      "epoch 265   loss 1.4770912568803936\n",
      "epoch 266   loss 1.4770726631926545\n",
      "epoch 267   loss 1.4770540795007503\n",
      "epoch 268   loss 1.4770355063843543\n",
      "epoch 269   loss 1.477016944411488\n",
      "epoch 270   loss 1.4769983941387337\n",
      "epoch 271   loss 1.4769798561114378\n",
      "epoch 272   loss 1.4769613308639138\n",
      "epoch 273   loss 1.476942818919639\n",
      "epoch 274   loss 1.4769243207914449\n",
      "epoch 275   loss 1.476905836981707\n",
      "epoch 276   loss 1.476887367982528\n",
      "epoch 277   loss 1.4768689142759204\n",
      "epoch 278   loss 1.4768504763339787\n",
      "epoch 279   loss 1.4768320546190565\n",
      "epoch 280   loss 1.4768136495839332\n",
      "epoch 281   loss 1.476795261671981\n",
      "epoch 282   loss 1.4767768913173265\n",
      "epoch 283   loss 1.476758538945011\n",
      "epoch 284   loss 1.4767402049711473\n",
      "epoch 285   loss 1.4767218898030712\n",
      "epoch 286   loss 1.4767035938394915\n",
      "epoch 287   loss 1.4766853174706407\n",
      "epoch 288   loss 1.4766670610784165\n",
      "epoch 289   loss 1.476648825036523\n",
      "epoch 290   loss 1.4766306097106139\n",
      "epoch 291   loss 1.4766124154584246\n",
      "epoch 292   loss 1.4765942426299095\n",
      "epoch 293   loss 1.4765760915673736\n",
      "epoch 294   loss 1.4765579626055987\n",
      "epoch 295   loss 1.4765398560719751\n",
      "epoch 296   loss 1.476521772286622\n",
      "epoch 297   loss 1.476503711562514\n",
      "epoch 298   loss 1.4764856742055976\n",
      "epoch 299   loss 1.4764676605149123\n",
      "epoch 300   loss 1.4764496707827073\n"
     ]
    }
   ],
   "source": [
    "data = readdlm(\"data/sprial.dat\");\n",
    "max_epoch = 300;\n",
    "batch_size = 30;\n",
    "hidden_size = 10;\n",
    "learning_rate = 1.0;\n",
    "net = TwoLayerNet{Float64}(2, hidden_size, 3)\n",
    "# @show model.a1l.W\n",
    "# @show model.a1l.b\n",
    "# @show model.a2l.W\n",
    "# @show model.a2l.b\n",
    "data_size = size(data)[1]\n",
    "max_iters = data_size // batch_size\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "loss_list = []\n",
    "\n",
    "for epoch in 1:max_epoch\n",
    "    # println(\"epoch $epoch\")\n",
    "    \n",
    "    # shuffle data\n",
    "    # idx = randperm(data_size)\n",
    "    # println(idx)\n",
    "    idx = 1:300\n",
    "    data = data[idx, :]\n",
    "    xorg = data[1:end, 1:2]\n",
    "    torg = one_hot(data[1:end, 3])\n",
    "    \n",
    "\n",
    "    # for each batch\n",
    "    for iters in 1:max_iters\n",
    "        iters = Int(iters)\n",
    "        ix = 1 + (iters - 1) * batch_size\n",
    "        bX = xorg[ix:(ix + batch_size) - 1, :]\n",
    "        bT = torg[ix:(ix + batch_size) - 1, :]\n",
    "        # print(bX)\n",
    "        \n",
    "        # @show bX\n",
    "         # display(bT)\n",
    "\n",
    "        # println(\"batch $iters, loss $ls\")\n",
    "        _loss, grad = gradient(net, bX, bT)\n",
    "        if iters == 1\n",
    "            # println(_loss)\n",
    "            # println(grad.W1)\n",
    "            # println(grad.b1)\n",
    "            # println(grad.W2)\n",
    "            # println(grad.b2)\n",
    "        end\n",
    "        applygradient!(net, grad, learning_rate)\n",
    "        # println(\"$ix $iters $_loss\")\n",
    "        total_loss += _loss\n",
    "        loss_count += 1\n",
    "        \n",
    "        # 定期的に学習経過を出力\n",
    "        if iters % 10 == 0\n",
    "            avg_loss = total_loss / loss_count\n",
    "            println(\"epoch $epoch   loss $(avg_loss)\")\n",
    "            push!(loss_list, avg_loss)\n",
    "            total_loss, loss_count = 0, 0\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both PyPlot and Base export \"axes\"; uses of it in module Main must be qualified\n"
     ]
    }
   ],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{PyCall.PyObject,1}:\n",
       " PyObject <matplotlib.lines.Line2D object at 0x0000000032BC5400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
