{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\".\\\\common\\\\layers.jl\")\n",
    "using Main.JLlayers\n",
    "using DelimitedFiles\n",
    "using Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read spiral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×3 Array{Float64,2}:\n",
       " -0.0     0.0     0.0\n",
       " -0.001   0.01    0.0\n",
       "  0.0051  0.0193  0.0\n",
       " -0.0004  0.03    0.0\n",
       "  0.0143  0.0374  0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = readdlm(\"data/sprial.dat\");\n",
    "data[1:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one_hot (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function one_hot(x::Array{Float64, 1}; num=3)\n",
    "    ans = zeros(size(x)[1], num)\n",
    "    for i in 1:size(x)[1]\n",
    "        idx = Int(x[i]) + 1\n",
    "        ans[i, idx] = 1\n",
    "    end\n",
    "    return ans\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 1;\n",
    "batch_size = 30;\n",
    "hidden_size = 10;\n",
    "learning_rate = 0.1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TwoLayerNet{Float64}(AffineLayer{Float64}([0.0160655 -0.0158389; -0.00600504 0.014894; … ; 0.00766652 0.0107925; 0.00181528 -0.0136185], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], #undef, [0.0 0.0; 0.0 0.0; … ; 0.0 0.0; 0.0 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), SigmoidLayer{Float64}(#undef), AffineLayer{Float64}([0.00261157 0.00626314 … 0.0115672 0.0250384; 0.0130931 0.00735298 … 0.00186794 -0.00643247; 0.000886271 0.00229753 … 0.011036 0.00910862], [0.0, 0.0, 0.0], #undef, [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0, 0.0, 0.0]), SoftmaxWithLossLayer{Float64}(5.0e-324, #undef, #undef))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data[:, 1:2]\n",
    "t = data[:, 3]\n",
    "to = one_hot(t)\n",
    "data_size = size(x)[1]\n",
    "max_iters = data_size // batch_size\n",
    "net = TwoLayerNet{Float64}(2, hidden_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "ename": "DimensionMismatch",
     "evalue": "DimensionMismatch(\"A has dimensions (31,2) but B has dimensions (10,2)\")",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch(\"A has dimensions (31,2) but B has dimensions (10,2)\")",
      "",
      "Stacktrace:",
      " [1] gemm_wrapper!(::Array{Float64,2}, ::Char, ::Char, ::Array{Float64,2}, ::Array{Float64,2}) at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.0\\LinearAlgebra\\src\\matmul.jl:439",
      " [2] mul! at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.0\\LinearAlgebra\\src\\matmul.jl:144 [inlined]",
      " [3] *(::Array{Float64,2}, ::Array{Float64,2}) at C:\\cygwin\\home\\Administrator\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.0\\LinearAlgebra\\src\\matmul.jl:142",
      " [4] forward(::AffineLayer{Float64}, ::Array{Float64,2}) at C:\\Users\\KO\\Program\\DLScratch2.jl\\common\\layers.jl:96",
      " [5] predict(::TwoLayerNet{Float64}, ::Array{Float64,2}) at C:\\Users\\KO\\Program\\DLScratch2.jl\\common\\layers.jl:129",
      " [6] loss(::TwoLayerNet{Float64}, ::Array{Float64,2}, ::Array{Float64,2}) at C:\\Users\\KO\\Program\\DLScratch2.jl\\common\\layers.jl:136",
      " [7] top-level scope at .\\In[6]:15"
     ]
    }
   ],
   "source": [
    "for epoch in 1:max_epoch\n",
    "    println(\"epoch $epoch\")\n",
    "    \n",
    "    # shuffle data\n",
    "    idx = randperm(data_size)\n",
    "    xorg = x[idx, :]\n",
    "    torg = to[idx, :]\n",
    "    \n",
    "    # for each batch\n",
    "    for iters in 1:(max_iters-1)\n",
    "        iters = Int(iters)\n",
    "        bX = xorg[iters * batch_size:(iters + 1) * batch_size, :]\n",
    "        bT = torg[iters * batch_size:(iters + 1) * batch_size, :]\n",
    "        \n",
    "        ls = loss(net, bX, bT)\n",
    "        println(\"batch $iters, loss $ls\")\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
